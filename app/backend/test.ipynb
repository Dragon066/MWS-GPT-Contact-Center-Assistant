{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfe0385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LLM_API_KEY\"] = \"sk-KNo006G2a48UVE3IxFlQEQ\"\n",
    "os.environ[\"LLM_BASE_URL\"] = \"https://api.gpt.mws.ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02db1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import ActionSuggestionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273811d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Полина\\MWS-GPT-Contact-Center-Assistant\\app\\backend\\agents\\ActionSuggestionAgent.py:13: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mИспользуя доступный инструмент lower, который преобразует текст в строчные буквы, я могу ответить на вопрос.\n",
      "Action: lower\n",
      "Action Input: БУКВЫ!!!\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mбуквы!!!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: буквы!!!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Привет, преобразуй этот текст в строчные БУКВЫ!!!',\n",
       " 'output': 'буквы!!!'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = ActionSuggestionAgent(verbose=True)\n",
    "agent.invoke('Привет, преобразуй этот текст в строчные БУКВЫ!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3801eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABC\n",
    "\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    LLM_API_KEY: str = os.getenv(\"LLM_API_KEY\")\n",
    "    LLM_BASE_URL: str = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "    def __new__(cls, verbose: bool = False): ...\n",
    "\n",
    "    def _llm(verbose: bool): ...\n",
    "\n",
    "    def _tools(): ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9281c0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OutputParser' from 'langchain.output_parsers' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\output_parsers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Runnable\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputParser  \u001b[38;5;66;03m# Пробуем использовать базовый OutputParser\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEmotionAgent\u001b[39;00m(Runnable):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OutputParser' from 'langchain.output_parsers' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\output_parsers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import OutputParser  # Пробуем использовать базовый OutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class EmotionAgent(Runnable):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"gpt-3.5-turbo\"),\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "            system_message=\"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\",\n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        # Используем OutputParser вместо JsonOutputParser или StrOutputParser\n",
    "        self.chain = self.prompt | self.llm | OutputParser()\n",
    "\n",
    "    def invoke(self, input_text: str) -> str:\n",
    "        return self.chain.invoke({\"text\": input_text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bdad4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionAgent(Runnable):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"gpt-3.5-turbo\"),\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "            system_message=\"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\",\n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        self.chain = self.prompt | self.llm  # Без парсера\n",
    "\n",
    "    def invoke(self, input_text: str) -> str:\n",
    "        response = self.chain.invoke({\"text\": input_text})\n",
    "        return response['text']  # Возвращаем текстовый ответ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71a43455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class EmotionAgent(Runnable):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "            system_message=\"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"\n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        # Здесь удаляем ненужные параметры и просто используем prompt и llm\n",
    "        self.chain = self.prompt | self.llm\n",
    "\n",
    "    def invoke(self, input_text: str) -> str:\n",
    "        response = self.chain.invoke({\"text\": input_text})\n",
    "        return response['text']  # Возвращаем текстовый ответ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b29ea17",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'BaseAgent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, AgentType, Tool, initialize_agent\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBaseAgent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseAgent\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'BaseAgent'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentExecutor, AgentType, Tool, initialize_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from BaseAgent import BaseAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3798bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m用户提供的是俄语文本，表达了他们感到非常沮丧，并不知道应该怎么做。虽然我有一个工具可以将文本转为小写，但在这个情境下，这个工具并不适用。我的目标是提供一些安慰和建议。\n",
      "\n",
      "Thought: 我需要提供安慰，并建议应对沮丧的方法。\n",
      "Final Answer: Я понимаю, что сейчас тебе трудно, и это нормально. Попробуй поговорить о своих чувствах с близкими тебе людьми, они могут поддержать и помочь найти решение. Также попробуй найти что-то, что приносит радость, например, заняться своим хобби или прогуляться на свежем воздухе. Помните, что чувства приходят и уходят, и ситуацию можно изменить.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Эмоция: {'input': 'Мне так грустно, я просто не знаю, что делать...', 'output': 'Я понимаю, что сейчас тебе трудно, и это нормально. Попробуй поговорить о своих чувствах с близкими тебе людьми, они могут поддержать и помочь найти решение. Также попробуй найти что-то, что приносит радость, например, заняться своим хобби или прогуляться на свежем воздухе. Помните, что чувства приходят и уходят, и ситуацию можно изменить.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "class EmotionAgent(Runnable):\n",
    "    def __new__(cls, verbose: bool = False):\n",
    "        llm = cls._llm(verbose)\n",
    "        tools = cls._tools()\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        return agent\n",
    "\n",
    "    def _llm(verbose: bool):\n",
    "        return ChatOpenAI(\n",
    "            base_url=BaseAgent.LLM_BASE_URL,\n",
    "            api_key=BaseAgent.LLM_API_KEY,\n",
    "            model=os.getenv(\"LLM_ACTIONSUGGESTION_AGENT\", \"qwen2.5-32b-instruct\"),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    def _tools():\n",
    "        def lower_tool(query: str):\n",
    "            return query.lower()\n",
    "\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"lower\",\n",
    "                func=lower_tool,\n",
    "                description=\"Возвращает текст строчными буквами\",\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        return tools\n",
    "emotion_agent = EmotionAgent(verbose=True)\n",
    "emotion = emotion_agent.invoke(\"Мне так грустно, я просто не знаю, что делать...\")\n",
    "print(\"Эмоция:\", emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88412d9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'EmotionAgent' has no attribute '_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 29\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ChatOpenAI(\n\u001b[0;32m     21\u001b[0m             base_url\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     22\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     23\u001b[0m             model\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM_EMOTION_AGENT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2.5-32b-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     24\u001b[0m             verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m     25\u001b[0m         )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Тестируем\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m emotion_agent \u001b[38;5;241m=\u001b[39m EmotionAgent(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m emotion \u001b[38;5;241m=\u001b[39m emotion_agent\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mМне так грустно, я просто не знаю, что делать...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭмоция:\u001b[39m\u001b[38;5;124m\"\u001b[39m, emotion)\n",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m, in \u001b[0;36mEmotionAgent.__new__\u001b[1;34m(cls, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      9\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_llm(verbose)\n\u001b[1;32m---> 10\u001b[0m     tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_tools()\n\u001b[0;32m     11\u001b[0m     agent \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[0;32m     12\u001b[0m         tools,\n\u001b[0;32m     13\u001b[0m         llm,\n\u001b[0;32m     14\u001b[0m         agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION,\n\u001b[0;32m     15\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'EmotionAgent' has no attribute '_tools'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain.agents import AgentExecutor, Tool, AgentType, initialize_agent\n",
    "\n",
    "class EmotionAgent(Runnable):\n",
    "    def __new__(cls, verbose: bool = False):\n",
    "        llm = cls._llm(verbose)\n",
    "        tools = cls._tools()\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        return agent\n",
    "\n",
    "    def _llm(verbose: bool):\n",
    "        return ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"qwen2.5-32b-instruct\"),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    def _tools():\n",
    "        def а(query: str):\n",
    "            # Простая логика для классификации эмоций, можно расширить или улучшить\n",
    "            emotions = {\n",
    "                \"гнев\": [\"злюсь\", \"ненавижу\", \"гнев\", \"злость\"],\n",
    "                \"радость\": [\"рад\", \"счастлив\", \"весело\", \"счастье\"],\n",
    "                \"нейтральное\": [\"нормально\", \"спокойно\", \"нейтрально\"],\n",
    "                \"тоска\": [\"грустно\", \"тоска\", \"печаль\", \"сожаление\"],\n",
    "                \"удивление\": [\"удивлен\", \"шокирован\", \"восторг\"]\n",
    "            }\n",
    "\n",
    "            for emotion, keywords in emotions.items():\n",
    "                if any(keyword in query.lower() for keyword in keywords):\n",
    "                    return emotion\n",
    "            return \"Неизвестно\"\n",
    "\n",
    "# Тестируем\n",
    "emotion_agent = EmotionAgent(verbose=True)\n",
    "emotion = emotion_agent.invoke(\"Мне так грустно, я просто не знаю, что делать...\")\n",
    "print(\"Эмоция:\", emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5aa9e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class EmotionAgent:\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"qwen2.5-32b-instruct\"),\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Выбери одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def invoke(self, input_text: str) -> str:\n",
    "        return self.chain.invoke({\"text\": input_text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c192121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents import AgentExecutor, AgentType, initialize_agent\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "\n",
    "class EmotionAgent(Runnable):\n",
    "    def __new__(cls, verbose: bool = False):\n",
    "        # Создаём LLM\n",
    "        llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"qwen2.5-32b-instruct\"),  # или qwen\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # Создаём промпт\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        # Связываем всё в цепочку\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "        return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3669ef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмоция: тоска\n"
     ]
    }
   ],
   "source": [
    "emotion_agent = EmotionAgent(verbose=True)\n",
    "emotion = emotion_agent.invoke(\"Мне так грустно, я просто не знаю, что делать...\")\n",
    "print(\"Эмоция:\", emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3086cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentAgent(BaseAgent):\n",
    "    def __new__(cls, verbose: bool = False):\n",
    "        llm = ChatOpenAI(\n",
    "            base_url=BaseAgent.LLM_BASE_URL,\n",
    "            api_key=BaseAgent.LLM_API_KEY,\n",
    "            model=\"qwen2.5-32b-instruct\",  \n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты выбираешь наиболее подходящую тему для сообщения пользователя.\"),\n",
    "            (\"system\", \"Темы: 'проблема с оплатой', 'жалоба', 'техническая проблема', 'вопрос по заказу', 'другое'.\"),\n",
    "            (\"system\", \"Отвечай только одной темой из списка, без пояснений.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b17dfd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Намерение: проблема с оплатой\n"
     ]
    }
   ],
   "source": [
    "intent_agent = IntentAgent(verbose=True)\n",
    "result = intent_agent.invoke(\"Я оплатил подписку, но сервис всё ещё недоступен\")\n",
    "print(\"Намерение:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89058774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмоция: гнев\n",
      "Намерение: проблема с оплатой\n"
     ]
    }
   ],
   "source": [
    "def process_request(request: str):\n",
    "    # Создаем агенты\n",
    "    emotion_agent = EmotionAgent(verbose=True)\n",
    "    intent_agent = IntentAgent(verbose=True)\n",
    "\n",
    "    # Получаем эмоцию и намерение\n",
    "    emotion = emotion_agent.invoke({\"text\": request})\n",
    "    intent = intent_agent.invoke({\"text\": request})\n",
    "\n",
    "    return emotion, intent\n",
    "\n",
    "# Тестируем\n",
    "request = \"Я оплатил подписку, но сервис всё ещё недоступен\"\n",
    "emotion, intent = process_request(request)\n",
    "\n",
    "print(\"Эмоция:\", emotion)\n",
    "print(\"Намерение:\", intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f58a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeVectorDB:\n",
    "    def __init__(self):\n",
    "        # заглушка\n",
    "        self.db = {\n",
    "            \"платежи\": \"Информация о процессах оплаты и подписке.\",\n",
    "            \"поручения\": \"Процесс выполнения и отслеживания поручений.\",\n",
    "            \"технические проблемы\": \"Общие инструкции по решению технических проблем.\",\n",
    "            \"возврат\": \"Процедуры возврата товаров и услуг.\",\n",
    "        }\n",
    "\n",
    "    def query(self, query: str):\n",
    "        # Здесь будет логика поиска по векторной базе, пока просто ищем по ключам\n",
    "        for key, value in self.db.items():\n",
    "            if key in query.lower():\n",
    "                return value\n",
    "        return \"Не удалось найти информацию по запросу.\"\n",
    "\n",
    "# Knowledge Agent\n",
    "class KnowledgeAgent(Runnable):\n",
    "    def __new__(cls, verbose: bool = False):\n",
    "        # Создаем LLM\n",
    "        llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=\"qwen2.5-32b-instruct\",  # как просила\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # Создаём промпт для общения с пользователем\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты агент, который ищет информацию в базе знаний.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "\n",
    "        # Создаем эмулатор работы с векторной БД\n",
    "        fake_db = FakeVectorDB()\n",
    "\n",
    "        # Логика обращения к базе данных\n",
    "        def query_db(query: str):\n",
    "            # Здесь будет интеграция с Qdrant в реальной версии\n",
    "            return fake_db.query(query)\n",
    "\n",
    "        # Связываем всё в цепочку\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "        # Возвращаем цепочку\n",
    "        return chain, query_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "337fd854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Намерение: проблема с оплатой\n",
      "Эмоция: гнев\n",
      "Ответ из базы знаний: Не удалось найти информацию по запросу.\n"
     ]
    }
   ],
   "source": [
    "def process_request(request: str):\n",
    "    # Создаем агента для определения намерения\n",
    "    intent_agent = IntentAgent(verbose=True)\n",
    "    intent = intent_agent.invoke(request)\n",
    "\n",
    "    # Создаем агента для анализа эмоций\n",
    "    emotion_agent = EmotionAgent(verbose=True)\n",
    "    emotion = emotion_agent.invoke(request)\n",
    "\n",
    "    # Создаем агента для поиска в базе знаний\n",
    "    knowledge_agent, query_db = KnowledgeAgent(verbose=True)\n",
    "    \n",
    "    # Используем данные о намерении и эмоции для поиска в базе знаний\n",
    "    knowledge_response = query_db(f\"Намерение: {intent}, Эмоция: {emotion}, Запрос: {request}\")\n",
    "    \n",
    "    return intent, emotion, knowledge_response\n",
    "\n",
    "# Тестируем\n",
    "request = \"Я оплатил подписку, но сервис всё ещё недоступен\"\n",
    "intent, emotion, knowledge_response = process_request(request)\n",
    "\n",
    "print(\"Намерение:\", intent)\n",
    "print(\"Эмоция:\", emotion)\n",
    "print(\"Ответ из базы знаний:\", knowledge_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e169aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Намерение: проблема с оплатой\n",
      "Эмоция: гнев\n",
      "Ответ из базы знаний: Не удалось найти информацию по запросу.\n"
     ]
    }
   ],
   "source": [
    "class EmotionAgent(Runnable):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=os.getenv(\"LLM_EMOTION_AGENT\", \"qwen2.5-32b-instruct\"),\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты — классификатор эмоций. Определи одну из: гнев, радость, нейтральное, тоска, удивление. Отвечай только одним словом.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def invoke(self, input_text: str):\n",
    "        return self.chain.invoke({\"text\": input_text})\n",
    "\n",
    "class IntentAgent(Runnable):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=\"qwen2.5-32b-instruct\",  \n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты выбираешь наиболее подходящую тему для сообщения пользователя.\"),\n",
    "            (\"system\", \"Темы: 'проблема с оплатой', 'жалоба', 'техническая проблема', 'вопрос по заказу', 'другое'.\"),\n",
    "            (\"system\", \"Отвечай только одной темой из списка, без пояснений.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def invoke(self, input_text: str):\n",
    "        return self.chain.invoke({\"text\": input_text})\n",
    "\n",
    "class FakeVectorDB:\n",
    "    def __init__(self):\n",
    "        self.db = {\n",
    "            \"платежи\": \"Информация о процессах оплаты и подписке.\",\n",
    "            \"поручения\": \"Процесс выполнения и отслеживания поручений.\",\n",
    "            \"технические проблемы\": \"Общие инструкции по решению технических проблем.\",\n",
    "            \"возврат\": \"Процедуры возврата товаров и услуг.\",\n",
    "        }\n",
    "\n",
    "    def query(self, query: str):\n",
    "        for key, value in self.db.items():\n",
    "            if key in query.lower():\n",
    "                return value\n",
    "        return \"Не удалось найти информацию по запросу.\"\n",
    "\n",
    "class KnowledgeAgent:\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=\"qwen2.5-32b-instruct\",\n",
    "            temperature=0,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Ты агент, который ищет информацию в базе знаний.\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "        self.db = FakeVectorDB()\n",
    "    \n",
    "    def query_db(self, query: str):\n",
    "        return self.db.query(query)\n",
    "    \n",
    "    def invoke(self, input_text: str):\n",
    "        return self.chain.invoke({\"text\": input_text})\n",
    "\n",
    "def process_request(request: str):\n",
    "    intent_agent = IntentAgent(verbose=True)\n",
    "    intent = intent_agent.invoke(request)\n",
    "\n",
    "    # Создаем агента для анализа эмоций\n",
    "    emotion_agent = EmotionAgent(verbose=True)\n",
    "    emotion = emotion_agent.invoke(request)\n",
    "\n",
    "    # Создаем агента для поиска в базе знаний\n",
    "    knowledge_agent = KnowledgeAgent(verbose=True)\n",
    "    \n",
    "    # Используем данные о намерении и эмоции для поиска в базе знаний\n",
    "    knowledge_response = knowledge_agent.query_db(f\"Намерение: {intent}, Эмоция: {emotion}, Запрос: {request}\")\n",
    "    \n",
    "    return intent, emotion, knowledge_response\n",
    "\n",
    "\n",
    "request = \"Я оплатил подписку, но сервис всё ещё недоступен\"\n",
    "intent, emotion, knowledge_response = process_request(request)\n",
    "\n",
    "print(\"Намерение:\", intent)\n",
    "print(\"Эмоция:\", emotion)\n",
    "print(\"Ответ из базы знаний:\", knowledge_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efaca23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionSuggestionAgent:\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "            api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "            model=\"qwen2.5-32b-instruct\",\n",
    "            temperature=0.3,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Ты — агент предложения действий в CRM. Формат ответа:\n",
    "            Thought: <анализ контекста>\n",
    "            Action: <рекомендуемое действие>\n",
    "            Answer: <готовый текст>\"\"\"),\n",
    "            (\"human\", \"\"\"Эмоция: {emotion}\n",
    "            Намерение: {intent}\n",
    "            Контекст: {context}\n",
    "            Запрос: \"{text}\" \"\"\")\n",
    "        ])\n",
    "\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def invoke(self, text: str, emotion: str, intent: str, context: str):\n",
    "        return self.chain.invoke({\n",
    "            \"text\": text,\n",
    "            \"emotion\": emotion,\n",
    "            \"intent\": intent,\n",
    "            \"context\": context\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace37a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryAgent(BaseAgent):\n",
    "    def __new__(cls, verbose: bool = False) -> AgentExecutor:\n",
    "        llm = cls._llm(verbose)\n",
    "        tools = cls._tools()\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        return agent\n",
    "\n",
    "    @staticmethod\n",
    "    def _llm(verbose: bool):\n",
    "        return ChatOpenAI(\n",
    "            base_url=BaseAgent.LLM_BASE_URL,\n",
    "            api_key=BaseAgent.LLM_API_KEY,\n",
    "            model=os.getenv(\"LLM_SUMMARY_AGENT\", \"qwen2.5-32b-instruct\"),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _tools():\n",
    "        # A tool to generate a summary of the conversation\n",
    "        def summarize_tool(conversation: str) -> str:\n",
    "            summary_prompt = f\"Сформируй краткое резюме диалога для автозаполнения CRM: {conversation}\"\n",
    "            return summary_prompt\n",
    "\n",
    "        # The 'summarize' tool uses the 'summarize_tool' function\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"summarize\",\n",
    "                func=summarize_tool,\n",
    "                description=\"Сформулирует краткое резюме для автозаполнения CRM.\"\n",
    "            ),\n",
    "        ]\n",
    "        return tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae369fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Запрос: Как я могу вернуть товар?\\nНамерение: вопрос по заказу\\nЭмоция: нейтральное', 'output': 'Клиент интересуется процессом возврата товара.'}\n"
     ]
    }
   ],
   "source": [
    "# Пример использования агентов в цепочке\n",
    "intent_agent = IntentAgent()\n",
    "emotion_agent = EmotionAgent()\n",
    "summary_agent = SummaryAgent()\n",
    "\n",
    "# Пример данных\n",
    "input_text = \"Как я могу вернуть товар?\"\n",
    "\n",
    "# 1. Определяем намерение\n",
    "intent = intent_agent.invoke(input_text)\n",
    "# 2. Анализируем эмоцию\n",
    "emotion = emotion_agent.invoke(input_text)\n",
    "# 3. Формируем резюме\n",
    "conversation_summary = summary_agent.invoke(f\"Запрос: {input_text}\\nНамерение: {intent}\\nЭмоция: {emotion}\")\n",
    "\n",
    "print(conversation_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fe4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
